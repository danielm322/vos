# @package _global_

# default configuration
defaults:
    - _self_
    - logger: mlflow.yaml
    - model: model.yaml

    # enable color logging
    # - override hydra/hydra_logging: colorlog
    # - override hydra/job_logging: colorlog

work_dir: ${hydra:runtime.cwd}
data_dir: ${work_dir}/MCD_evaluation_data/
log_dir: logs_hydra/runs/${logger.mlflow.experiment_name}/${now:%Y-%m-%d_%H-%M-%S}

# Datasets
# InD: either cifar10 or svhn
ind_dataset: "cifar10"
ood_dataset: "svhn"
bdd_valid_mcd_samples: "cifar10/cifar10_valid_Conv_8000_1024_10_mcd_samples.pt"
bdd_test_mcd_samples: "cifar10/cifar10_test_Conv_2000_1024_10_mcd_samples.pt"
ood_mcd_samples: "cifar10/gtsrb_test_Conv_2274_1024_10_mcd_samples.pt"
# Precomputed entropies
bdd_entropy_valid: "cifar10/cifar10_valid_Conv_8000_1024_10_mcd_h_z_samples.npy"
bdd_entropy_test: "cifar10/cifar10_test_Conv_2000_1024_10_mcd_h_z_samples.npy"
ood_entropy_test: "cifar10/gtsrb_ood_test_Conv_2274_1024_10_mcd_h_z_samples.npy"
# Eval configuration
precomputed_mcd_runs: 10
# Number of Monte Carlo Dropout runs to use.
n_mcd_runs: 10
# This parameter controls the raw number of proposals from RPN to be used.
# If it is <1000, a random sampler will take that number of samples to continue with the rest of the algorithm
use_n_proposals: 1024
max_n_proposals: 1024
#n_pca_components: [1, 2, 3, 4, 6, 8, 10, 12]
n_pca_components: [1, 2, 3, 4, 6, 10, 14, 16, 18, 20, 24]
#n_pca_components: [2, 4, 8, 12, 16, 20, 24, 28, 32]
n_pacmap_neighbors: 10
#n_pacmap_components: [2, 3, 4, 5, 6, 8, 10, 12]
n_pacmap_components: [2, 3, 4, 6, 8, 12]
normalize_kde_prediction: False
seed: 42
layer_type: "Conv"
# Reduction method for the hooked MCD samples: either 'mean' or 'avgpool'
reduction_method: "avgpool"
model_version: 17
parallel_entropy_calculation: True
extra_data_augmentations: True

hydra:
    # output paths for hydra logs
    run:
        dir: ${log_dir}

    sweep:
        dir: logs_hydra/multiruns/${now:%Y-%m-%d_%H-%M-%S}
        subdir: ${hydra.job.num}
